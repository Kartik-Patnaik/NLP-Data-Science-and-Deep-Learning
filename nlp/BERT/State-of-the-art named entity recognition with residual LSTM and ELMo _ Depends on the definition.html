<!DOCTYPE html>
<!-- saved from url=(0095)https://www.depends-on-the-definition.com/named-entity-recognition-with-residual-lstm-and-elmo/ -->
<html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style id="stndz-style"></style><meta name="viewport" content="width=device-width,initial-scale=1"><title>State-of-the-art named entity recognition with residual LSTM and ELMo | Depends on the definition</title><meta property="og:title" content="State-of-the-art named entity recognition with residual LSTM and ELMo - Depends on the definition"><meta property="og:description" content="This is the sixth post in my series about named entity recognition. This time I’m going to show you some cutting edge stuff. We will use a residual LSTM network together with ELMo embeddings, developed at Allen NLP. You will learn how to wrap a tensorflow hub pre-trained model to work with keras. The resulting model with give you state-of-the-art performance on the named entity recognition task."><meta property="og:url" content="https://www.depends-on-the-definition.com/named-entity-recognition-with-residual-lstm-and-elmo/"><meta property="og:site_name" content="Depends on the definition"><meta property="og:type" content="article"><meta property="og:image" content="https://www.depends-on-the-definition.com/images/mstile-150x150.png"><meta property="article:section" content="Posts"><meta property="article:tag" content="Named entity recognition"><meta property="article:tag" content="NLP"><meta property="article:tag" content="deep learning"><meta property="article:published_time" content="2018-07-01T00:00:00Z"><meta property="article:modified_time" content="2020-04-20T17:55:47+02:00"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@tobias_sterbak"><meta name="twitter:creator" content="@tobias_sterbak"><link href="https://www.depends-on-the-definition.com/index.xml" rel="alternate" type="application/rss+xml" title="Depends on the definition"><link rel="stylesheet" href="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/style.css"><link rel="stylesheet" href="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/custom.css"><link rel="apple-touch-icon" sizes="180x180" href="https://www.depends-on-the-definition.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://www.depends-on-the-definition.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://www.depends-on-the-definition.com/favicon-16x16.png"><link rel="manifest" href="https://www.depends-on-the-definition.com/site.webmanifest"><link rel="mask-icon" href="https://www.depends-on-the-definition.com/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" href="https://www.depends-on-the-definition.com/named-entity-recognition-with-residual-lstm-and-elmo/"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"><script src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/179a4f50f65f1c84b1de67671b83ec44a44e0c14.js.download"></script><script async="" defer="" data-domain="depends-on-the-definition.com" src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/index.js.download"></script><script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script><script src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/feather.min.js.download"></script><meta name="google-site-verification" content="545p683uBYQ_3gDVcCO4hQZCIFalfxuX_LneJP9lxFk"></head><body data-gr-c-s-loaded="true"><div class="progress-header"><div class="progress-container" style="position:fixed;top:0;z-index:2"><div class="progress-bar" id="myBar" style="width: 0%;"></div></div></div><section class="section"><div class="container"><nav id="nav-main" class="nav"><div id="nav-name" class="nav-left"><a id="nav-anchor" class="nav-item" href="https://www.depends-on-the-definition.com/"><img src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/header_icon_d.png"><h1 id="nav-heading" class="title is-4">epends on the definition</h1></a></div><div class="nav-right"><nav id="nav-items" class="nav-item level is-mobile"><a class="level-item" aria-label="about" href="https://www.depends-on-the-definition.com/about/"><span class="icon"><i><svg viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><circle cx="12" cy="12" r="10"></circle><path d="M9.09 9a3 3 0 015.83 1c0 2-3 3-3 3"></path><line x1="12" y1="17" x2="12.01" y2="17"></line></svg></i></span></a><a class="level-item" aria-label="work-with-me" href="https://www.depends-on-the-definition.com/work-with-me/"><span class="icon"><i><svg viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></i></span></a><a class="level-item" aria-label="twitter" href="https://twitter.com/tobias_sterbak" target="_blank" rel="noopener"><span class="icon"><i><svg viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"></path></svg></i></span></a><a class="level-item" aria-label="github" href="https://github.com/tsterbak" target="_blank" rel="noopener"><span class="icon"><i><svg viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77a5.44 5.44.0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"></path></svg></i></span></a><a class="level-item" aria-label="linkedin" href="https://linkedin.com/in/tobias-sterbak" target="_blank" rel="noopener"><span class="icon"><i><svg viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path stroke-width="1.8" d="m5.839218 4.101561c0 1.211972-.974141 2.194011-2.176459 2.194011S1.4863 5.313533 1.4863 4.101561c0-1.211094.974141-2.194011 2.176459-2.194011s2.176459.982917 2.176459 2.194011zm.017552 3.94922h-4.388022v14.04167H5.85677V8.050781zm7.005038.0H8.501869v14.04167h4.360816v-7.370999c0-4.098413 5.291077-4.433657 5.291077.0v7.370999h4.377491v-8.89101c0-6.915523-7.829986-6.66365-9.669445-3.259423V8.050781z"></path></svg></i></span></a><a class="level-item" aria-label="email" href="mailto:info@depends-on-the-definition.com" target="_blank" rel="noopener"><span class="icon"><i><svg viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline></svg></i></span></a></nav></div></nav><nav class="nav"></nav></div><script src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/navicon-shift.js.download"></script></section><section class="section"><div class="toc"><aside><nav id="TableOfContents"><ul><li><a href="https://www.depends-on-the-definition.com/named-entity-recognition-with-residual-lstm-and-elmo/#what-are-elmo-embeddings">What are ELMo embeddings?</a></li><li><a href="https://www.depends-on-the-definition.com/named-entity-recognition-with-residual-lstm-and-elmo/#data-preperation">Data preperation</a></li><li><a href="https://www.depends-on-the-definition.com/named-entity-recognition-with-residual-lstm-and-elmo/#the-elmo-residual-lstm-model">The ELMo residual LSTM model</a></li></ul></nav></aside></div><div class="container"><div><button onclick="topFunction()" id="myBtn" title="Go to top" style="display: none; overflow: visible;">
<svg xmlns="http://www.w3.org/2000/svg" width="54" height="54" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-up"><polyline points="18 15 12 9 6 15"></polyline></svg><script>feather.replace({'stroke-width':1,width:"54",height:"54",viewBox:"0 0 24 24"})</script></button></div><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href="https://www.depends-on-the-definition.com/tags/named-entity-recognition">#Named entity recognition</a>
| <a class="subtitle is-6" href="https://www.depends-on-the-definition.com/tags/nlp">#NLP</a>
| <a class="subtitle is-6" href="https://www.depends-on-the-definition.com/tags/deep-learning">#deep learning</a></div><h2 class="subtitle is-6">2018-07-01</h2><br><h1 class="title">State-of-the-art named entity recognition with residual LSTM and ELMo</h1><div class="content"><p>This is the sixth post in my <a href="https://www.depends-on-the-definition.com/tags/named-entity-recognition/">series about named entity recognition</a>. If you haven’t seen the last five, have a look now. The last time we used <a href="https://www.depends-on-the-definition.com/lstm-with-char-embeddings-for-ner/">character embeddings and a LSTM</a> to model the sequence structure of our sentences and predict the named entities. This time I’m going to show you some cutting edge stuff. We will use a residual LSTM network together with ELMo embeddings [1], developed at Allen NLP. You will learn how to wrap a tensorflow hub pretrained model to work with keras. The resulting model with give you state-of-the-art performance on the named entity recognition task.</p><h2 id="what-are-elmo-embeddings">What are ELMo embeddings?</h2><p>ELMo embeddings are embeddings from a language model trained on the 1 Billion Word Benchmark and the pretrained version is available on tensorflow hub. Unlike most widely used word embeddings, ELMo word representations are functions of the entire input sentence. They are computed on top of two-layer bidirectional language model with character convolutions, as a linear function of the internal network states. Concretely, ELMos use a pre-trained, multi-layer, bi-directional, LSTM-based language model and extract the hidden state of each layer for the input sequence of words. Then, they compute a weighted sum of those hidden states to obtain an embedding for each word. The weight of each hidden state is task-dependent and is learned.
ELMo improves the performance of models across a wide range of tasks, spanning from question answering and sentiment analysis to named entity recognition. This setup allows us to do semi-supervised learning, where the biLM is pre-trained at a large scale and easily incorporated into a wide range of existing neural NLP architectures.</p><p>I suggest having a look at the great paper <a href="https://arxiv.org/pdf/1802.05365.pdf">“Deep contextualized word representations”</a>.</p><h2 id="data-preperation">Data preperation</h2><p>Let’s start by loading and preparing the data. If you are familiar with the last post of this series, you can skip this part and jump directly to the model setup.
If you want to run the tutorial yourself, you can <a href="https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus#ner_dataset.csv">find the dataset here</a>.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:700">import</span> <span style="color:#0e84b5;font-weight:700">pandas</span> <span style="color:#007020;font-weight:700">as</span> <span style="color:#0e84b5;font-weight:700">pd</span>
<span style="color:#007020;font-weight:700">import</span> <span style="color:#0e84b5;font-weight:700">numpy</span> <span style="color:#007020;font-weight:700">as</span> <span style="color:#0e84b5;font-weight:700">np</span>
<span style="color:#007020;font-weight:700">import</span> <span style="color:#0e84b5;font-weight:700">matplotlib.pyplot</span> <span style="color:#007020;font-weight:700">as</span> <span style="color:#0e84b5;font-weight:700">plt</span>
plt<span style="color:#666">.</span>style<span style="color:#666">.</span>use(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">ggplot</span><span style="color:#4070a0">"</span>)

data <span style="color:#666">=</span> pd<span style="color:#666">.</span>read_csv(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">ner_dataset.csv</span><span style="color:#4070a0">"</span>, encoding<span style="color:#666">=</span><span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">latin1</span><span style="color:#4070a0">"</span>)
data <span style="color:#666">=</span> data<span style="color:#666">.</span>fillna(method<span style="color:#666">=</span><span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">ffill</span><span style="color:#4070a0">"</span>)
data<span style="color:#666">.</span>tail(<span style="color:#40a070">10</span>)
</code></pre></div><div><style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}<pre><code>.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</code></pre><p></style><p></p><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>Sentence #</th><th>Word</th><th>POS</th><th>Tag</th></tr></thead><tbody><tr><th>1048565</th><td>Sentence: 47958</td><td>impact</td><td>NN</td><td>O</td></tr><tr><th>1048566</th><td>Sentence: 47958</td><td>.</td><td>.</td><td>O</td></tr><tr><th>1048567</th><td>Sentence: 47959</td><td>Indian</td><td>JJ</td><td>B-gpe</td></tr><tr><th>1048568</th><td>Sentence: 47959</td><td>forces</td><td>NNS</td><td>O</td></tr><tr><th>1048569</th><td>Sentence: 47959</td><td>said</td><td>VBD</td><td>O</td></tr><tr><th>1048570</th><td>Sentence: 47959</td><td>they</td><td>PRP</td><td>O</td></tr><tr><th>1048571</th><td>Sentence: 47959</td><td>responded</td><td>VBD</td><td>O</td></tr><tr><th>1048572</th><td>Sentence: 47959</td><td>to</td><td>TO</td><td>O</td></tr><tr><th>1048573</th><td>Sentence: 47959</td><td>the</td><td>DT</td><td>O</td></tr><tr><th>1048574</th><td>Sentence: 47959</td><td>attack</td><td>NN</td><td>O</td></tr></tbody></table></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">words <span style="color:#666">=</span> <span style="color:#007020">list</span>(<span style="color:#007020">set</span>(data[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">Word</span><span style="color:#4070a0">"</span>]<span style="color:#666">.</span>values))
words<span style="color:#666">.</span>append(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">ENDPAD</span><span style="color:#4070a0">"</span>)
n_words <span style="color:#666">=</span> <span style="color:#007020">len</span>(words); n_words
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>35179
</code></pre><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">tags <span style="color:#666">=</span> <span style="color:#007020">list</span>(<span style="color:#007020">set</span>(data[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">Tag</span><span style="color:#4070a0">"</span>]<span style="color:#666">.</span>values))
n_tags <span style="color:#666">=</span> <span style="color:#007020">len</span>(tags); n_tags
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>17
</code></pre><p>So we have 47959 sentences containing 35178 different words with 17 different tags. We use the SentenceGetter class from last post to retrieve sentences with their labels.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:700">class</span> <span style="color:#0e84b5;font-weight:700">SentenceGetter</span>(<span style="color:#007020">object</span>):
    
    <span style="color:#007020;font-weight:700">def</span> __init__(self, data):
        self<span style="color:#666">.</span>n_sent <span style="color:#666">=</span> <span style="color:#40a070">1</span>
        self<span style="color:#666">.</span>data <span style="color:#666">=</span> data
        self<span style="color:#666">.</span>empty <span style="color:#666">=</span> False
        agg_func <span style="color:#666">=</span> <span style="color:#007020;font-weight:700">lambda</span> s: [(w, p, t) <span style="color:#007020;font-weight:700">for</span> w, p, t <span style="color:#007020;font-weight:700">in</span> <span style="color:#007020">zip</span>(s[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">Word</span><span style="color:#4070a0">"</span>]<span style="color:#666">.</span>values<span style="color:#666">.</span>tolist(),
                                                           s[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">POS</span><span style="color:#4070a0">"</span>]<span style="color:#666">.</span>values<span style="color:#666">.</span>tolist(),
                                                           s[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">Tag</span><span style="color:#4070a0">"</span>]<span style="color:#666">.</span>values<span style="color:#666">.</span>tolist())]
        self<span style="color:#666">.</span>grouped <span style="color:#666">=</span> self<span style="color:#666">.</span>data<span style="color:#666">.</span>groupby(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">Sentence #</span><span style="color:#4070a0">"</span>)<span style="color:#666">.</span>apply(agg_func)
        self<span style="color:#666">.</span>sentences <span style="color:#666">=</span> [s <span style="color:#007020;font-weight:700">for</span> s <span style="color:#007020;font-weight:700">in</span> self<span style="color:#666">.</span>grouped]
    
    <span style="color:#007020;font-weight:700">def</span> <span style="color:#06287e">get_next</span>(self):
        <span style="color:#007020;font-weight:700">try</span>:
            s <span style="color:#666">=</span> self<span style="color:#666">.</span>grouped[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">Sentence: {}</span><span style="color:#4070a0">"</span><span style="color:#666">.</span>format(self<span style="color:#666">.</span>n_sent)]
            self<span style="color:#666">.</span>n_sent <span style="color:#666">+</span><span style="color:#666">=</span> <span style="color:#40a070">1</span>
            <span style="color:#007020;font-weight:700">return</span> s
        <span style="color:#007020;font-weight:700">except</span>:
            <span style="color:#007020;font-weight:700">return</span> None
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">getter <span style="color:#666">=</span> SentenceGetter(data)
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">sent <span style="color:#666">=</span> getter<span style="color:#666">.</span>get_next()
</code></pre></div><p>This is how a sentence looks now.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:700">print</span>(sent)
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]
</code></pre><p>Okay, that looks as expected, now get all sentences.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">sentences <span style="color:#666">=</span> getter<span style="color:#666">.</span>sentences
</code></pre></div><p>For the use of neural nets (at least with keras, there is no theoretical reason) we need to use equal-length input sequences. So we are going to pad our sentences to a length of 50. But first we need a dictionary of tags to map our labels to numbers.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">max_len <span style="color:#666">=</span> <span style="color:#40a070">50</span>
tag2idx <span style="color:#666">=</span> {t: i <span style="color:#007020;font-weight:700">for</span> i, t <span style="color:#007020;font-weight:700">in</span> <span style="color:#007020">enumerate</span>(tags)}
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">tag2idx[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">B-geo</span><span style="color:#4070a0">"</span>]
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>14
</code></pre><p>To apply the EMLo embedding from tensorflow hub, we have to use strings as input. So we take the tokenized sentences and pad them to the desired length.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X <span style="color:#666">=</span> [[w[<span style="color:#40a070">0</span>] <span style="color:#007020;font-weight:700">for</span> w <span style="color:#007020;font-weight:700">in</span> s] <span style="color:#007020;font-weight:700">for</span> s <span style="color:#007020;font-weight:700">in</span> sentences]
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">new_X <span style="color:#666">=</span> []
<span style="color:#007020;font-weight:700">for</span> seq <span style="color:#007020;font-weight:700">in</span> X:
    new_seq <span style="color:#666">=</span> []
    <span style="color:#007020;font-weight:700">for</span> i <span style="color:#007020;font-weight:700">in</span> <span style="color:#007020">range</span>(max_len):
        <span style="color:#007020;font-weight:700">try</span>:
            new_seq<span style="color:#666">.</span>append(seq[i])
        <span style="color:#007020;font-weight:700">except</span>:
            new_seq<span style="color:#666">.</span>append(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">__PAD__</span><span style="color:#4070a0">"</span>)
    new_X<span style="color:#666">.</span>append(new_seq)
X <span style="color:#666">=</span> new_X
</code></pre></div><p>This is how a input sample looks like now.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:700">print</span>(X[<span style="color:#40a070">1</span>])
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>['Iranian', 'officials', 'say', 'they', 'expect', 'to', 'get', 'access', 'to', 'sealed', 'sensitive', 'parts', 'of', 'the', 'plant', 'Wednesday', ',', 'after', 'an', 'IAEA', 'surveillance', 'system', 'begins', 'functioning', '.', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__']
</code></pre><p>And we need to do the same for our tag sequence, but map the string to an integer.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y <span style="color:#666">=</span> [[tag2idx[w[<span style="color:#40a070">2</span>]] <span style="color:#007020;font-weight:700">for</span> w <span style="color:#007020;font-weight:700">in</span> s] <span style="color:#007020;font-weight:700">for</span> s <span style="color:#007020;font-weight:700">in</span> sentences]
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:700">from</span> <span style="color:#0e84b5;font-weight:700">keras.preprocessing.sequence</span> <span style="color:#007020;font-weight:700">import</span> pad_sequences
y <span style="color:#666">=</span> pad_sequences(maxlen<span style="color:#666">=</span>max_len, sequences<span style="color:#666">=</span>y, padding<span style="color:#666">=</span><span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">post</span><span style="color:#4070a0">"</span>, value<span style="color:#666">=</span>tag2idx[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">O</span><span style="color:#4070a0">"</span>])
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>Using TensorFlow backend.
</code></pre><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y[<span style="color:#40a070">1</span>]
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>array([ 0, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 11, 15,
       15, 15,  4, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],
      dtype=int32)
</code></pre><p>We split in train and test set.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:700">from</span> <span style="color:#0e84b5;font-weight:700">sklearn.model_selection</span> <span style="color:#007020;font-weight:700">import</span> train_test_split
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X_tr, X_te, y_tr, y_te <span style="color:#666">=</span> train_test_split(X, y, test_size<span style="color:#666">=</span><span style="color:#40a070">0.1</span>, random_state<span style="color:#666">=</span><span style="color:#40a070">2018</span>)
</code></pre></div><h2 id="the-elmo-residual-lstm-model">The ELMo residual LSTM model</h2><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">batch_size <span style="color:#666">=</span> <span style="color:#40a070">32</span>
</code></pre></div><p>Now we can initialize the ELMo embedding from tensorflow hub.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:700">import</span> <span style="color:#0e84b5;font-weight:700">tensorflow</span> <span style="color:#007020;font-weight:700">as</span> <span style="color:#0e84b5;font-weight:700">tf</span>
<span style="color:#007020;font-weight:700">import</span> <span style="color:#0e84b5;font-weight:700">tensorflow_hub</span> <span style="color:#007020;font-weight:700">as</span> <span style="color:#0e84b5;font-weight:700">hub</span>
<span style="color:#007020;font-weight:700">from</span> <span style="color:#0e84b5;font-weight:700">keras</span> <span style="color:#007020;font-weight:700">import</span> backend <span style="color:#007020;font-weight:700">as</span> K
</code></pre></div><p>Initialize the tensorflow session.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">sess <span style="color:#666">=</span> tf<span style="color:#666">.</span>Session()
K<span style="color:#666">.</span>set_session(sess)
</code></pre></div><p>If you run the following code for the first time, it will download the pretrained model. This might take a while.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">elmo_model <span style="color:#666">=</span> hub<span style="color:#666">.</span>Module(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">https://tfhub.dev/google/elmo/2</span><span style="color:#4070a0">"</span>, trainable<span style="color:#666">=</span>True)
sess<span style="color:#666">.</span>run(tf<span style="color:#666">.</span>global_variables_initializer())
sess<span style="color:#666">.</span>run(tf<span style="color:#666">.</span>tables_initializer())
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>INFO:tensorflow:Initialize variable module_1/aggregation/scaling:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with aggregation/scaling
INFO:tensorflow:Initialize variable module_1/aggregation/weights:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with aggregation/weights
INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_0:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_0
INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_1:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_1
INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_2:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_2
INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_3:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_3
INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_4:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_4
INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_5:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_5
INFO:tensorflow:Initialize variable module_1/bilm/CNN/W_cnn_6:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_6
INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_0:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_0
INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_1:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_1
INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_2:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_2
INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_3:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_3
INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_4:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_4
INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_5:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_5
INFO:tensorflow:Initialize variable module_1/bilm/CNN/b_cnn_6:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_6
INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/W_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/W_carry
INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/W_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/W_transform
INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/b_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/b_carry
INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_0/b_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/b_transform
INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/W_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/W_carry
INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/W_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/W_transform
INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/b_carry:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/b_carry
INFO:tensorflow:Initialize variable module_1/bilm/CNN_high_1/b_transform:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/b_transform
INFO:tensorflow:Initialize variable module_1/bilm/CNN_proj/W_proj:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_proj/W_proj
INFO:tensorflow:Initialize variable module_1/bilm/CNN_proj/b_proj:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_proj/b_proj
INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias
INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel
INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel
INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias
INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel
INFO:tensorflow:Initialize variable module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel
INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias
INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel
INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel
INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias
INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel
INFO:tensorflow:Initialize variable module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel
INFO:tensorflow:Initialize variable module_1/bilm/char_embed:0 from checkpoint b'/tmp/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/char_embed
</code></pre><p>Now we create a function that takes a sequence of strings and returns a sequence of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1024</mn></mrow><annotation encoding="application/x-tex">1024</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span></span></span></span></span>-dimensional vectors of the ELMo embedding. We will later use this function with the Lambda layer of keras to get the embedding sequence.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:700">def</span> <span style="color:#06287e">ElmoEmbedding</span>(x):
    <span style="color:#007020;font-weight:700">return</span> elmo_model(inputs<span style="color:#666">=</span>{
                            <span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">tokens</span><span style="color:#4070a0">"</span>: tf<span style="color:#666">.</span>squeeze(tf<span style="color:#666">.</span>cast(x, tf<span style="color:#666">.</span>string)),
                            <span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">sequence_len</span><span style="color:#4070a0">"</span>: tf<span style="color:#666">.</span>constant(batch_size<span style="color:#666">*</span>[max_len])
                      },
                      signature<span style="color:#666">=</span><span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">tokens</span><span style="color:#4070a0">"</span>,
                      as_dict<span style="color:#666">=</span>True)[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">elmo</span><span style="color:#4070a0">"</span>]
</code></pre></div><p>Now we can fit a residual LSTM network with an embedding layer.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007020;font-weight:700">from</span> <span style="color:#0e84b5;font-weight:700">keras.models</span> <span style="color:#007020;font-weight:700">import</span> Model, Input
<span style="color:#007020;font-weight:700">from</span> <span style="color:#0e84b5;font-weight:700">keras.layers.merge</span> <span style="color:#007020;font-weight:700">import</span> add
<span style="color:#007020;font-weight:700">from</span> <span style="color:#0e84b5;font-weight:700">keras.layers</span> <span style="color:#007020;font-weight:700">import</span> LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">input_text <span style="color:#666">=</span> Input(shape<span style="color:#666">=</span>(max_len,), dtype<span style="color:#666">=</span>tf<span style="color:#666">.</span>string)
embedding <span style="color:#666">=</span> Lambda(ElmoEmbedding, output_shape<span style="color:#666">=</span>(None, <span style="color:#40a070">1024</span>))(input_text)
x <span style="color:#666">=</span> Bidirectional(LSTM(units<span style="color:#666">=</span><span style="color:#40a070">512</span>, return_sequences<span style="color:#666">=</span>True,
                       recurrent_dropout<span style="color:#666">=</span><span style="color:#40a070">0.2</span>, dropout<span style="color:#666">=</span><span style="color:#40a070">0.2</span>))(embedding)
x_rnn <span style="color:#666">=</span> Bidirectional(LSTM(units<span style="color:#666">=</span><span style="color:#40a070">512</span>, return_sequences<span style="color:#666">=</span>True,
                           recurrent_dropout<span style="color:#666">=</span><span style="color:#40a070">0.2</span>, dropout<span style="color:#666">=</span><span style="color:#40a070">0.2</span>))(x)
x <span style="color:#666">=</span> add([x, x_rnn])  <span style="color:#60a0b0;font-style:italic"># residual connection to the first biLSTM</span>
out <span style="color:#666">=</span> TimeDistributed(Dense(n_tags, activation<span style="color:#666">=</span><span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">softmax</span><span style="color:#4070a0">"</span>))(x)
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">model <span style="color:#666">=</span> Model(input_text, out)
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">model<span style="color:#666">.</span>compile(optimizer<span style="color:#666">=</span><span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">adam</span><span style="color:#4070a0">"</span>, loss<span style="color:#666">=</span><span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">sparse_categorical_crossentropy</span><span style="color:#4070a0">"</span>, metrics<span style="color:#666">=</span>[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">accuracy</span><span style="color:#4070a0">"</span>])
</code></pre></div><p><strong>Comment:</strong>
We need to make the number of samples divisible by the batch_size to make it work. Otherwise the last batch in keras will break the architecture. I haven’t found a fix for this yet. Please tell me if you have an idea.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X_tr, X_val <span style="color:#666">=</span> X_tr[:<span style="color:#40a070">1213</span><span style="color:#666">*</span>batch_size], X_tr[<span style="color:#666">-</span><span style="color:#40a070">135</span><span style="color:#666">*</span>batch_size:]
y_tr, y_val <span style="color:#666">=</span> y_tr[:<span style="color:#40a070">1213</span><span style="color:#666">*</span>batch_size], y_tr[<span style="color:#666">-</span><span style="color:#40a070">135</span><span style="color:#666">*</span>batch_size:]
y_tr <span style="color:#666">=</span> y_tr<span style="color:#666">.</span>reshape(y_tr<span style="color:#666">.</span>shape[<span style="color:#40a070">0</span>], y_tr<span style="color:#666">.</span>shape[<span style="color:#40a070">1</span>], <span style="color:#40a070">1</span>)
y_val <span style="color:#666">=</span> y_val<span style="color:#666">.</span>reshape(y_val<span style="color:#666">.</span>shape[<span style="color:#40a070">0</span>], y_val<span style="color:#666">.</span>shape[<span style="color:#40a070">1</span>], <span style="color:#40a070">1</span>)
</code></pre></div><p>And now we can finally fit the model. Since the computation of ELMo is pretty computational expensive, you better fit the model on a GPU.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">history <span style="color:#666">=</span> model<span style="color:#666">.</span>fit(np<span style="color:#666">.</span>array(X_tr), y_tr, validation_data<span style="color:#666">=</span>(np<span style="color:#666">.</span>array(X_val), y_val),
                    batch_size<span style="color:#666">=</span>batch_size, epochs<span style="color:#666">=</span><span style="color:#40a070">5</span>, verbose<span style="color:#666">=</span><span style="color:#40a070">1</span>)
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>Train on 38816 samples, validate on 4320 samples
Epoch 1/5
38846/38846 [==============================] - 247s - loss: 0.1419 - acc: 0.9640 - val_loss: 0.0630 - val_acc: 0.9815
Epoch 2/5
38846/38846 [==============================] - 250s - loss: 0.0552 - acc: 0.9840 - val_loss: 0.0513 - val_acc: 0.9847
Epoch 3/5
38846/38846 [==============================] - 245s - loss: 0.0462 - acc: 0.9865 - val_loss: 0.0480 - val_acc: 0.9857
Epoch 4/5
38846/38846 [==============================] - 245s - loss: 0.0417 - acc: 0.9878 - val_loss: 0.0462 - val_acc: 0.9905
Epoch 5/5
38846/38846 [==============================] - 246s - loss: 0.0388 - acc: 0.9886 - val_loss: 0.0446 - val_acc: 0.9920
</code></pre><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">hist <span style="color:#666">=</span> pd<span style="color:#666">.</span>DataFrame(history<span style="color:#666">.</span>history)
</code></pre></div><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#666">.</span>figure(figsize<span style="color:#666">=</span>(<span style="color:#40a070">12</span>,<span style="color:#40a070">12</span>))
plt<span style="color:#666">.</span>plot(hist[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">acc</span><span style="color:#4070a0">"</span>])
plt<span style="color:#666">.</span>plot(hist[<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">val_acc</span><span style="color:#4070a0">"</span>])
plt<span style="color:#666">.</span>title(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">Learning curves</span><span style="color:#4070a0">"</span>)
plt<span style="color:#666">.</span>legend()
plt<span style="color:#666">.</span>show()
</code></pre></div><p><img src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/named-entity-recognition-with-residual-lstm-and-elmo_52_0.png" alt="png"></p><p>Now look at some predictions.</p><button class="copy-code-button" type="button">Copy</button><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">i <span style="color:#666">=</span> <span style="color:#40a070">19</span>
p <span style="color:#666">=</span> model<span style="color:#666">.</span>predict(np<span style="color:#666">.</span>array(X_te[i:i<span style="color:#666">+</span>batch_size]))[<span style="color:#40a070">0</span>]
p <span style="color:#666">=</span> np<span style="color:#666">.</span>argmax(p, axis<span style="color:#666">=</span><span style="color:#666">-</span><span style="color:#40a070">1</span>)
<span style="color:#007020;font-weight:700">print</span>(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">{:15} {:5}: ({})</span><span style="color:#4070a0">"</span><span style="color:#666">.</span>format(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">Word</span><span style="color:#4070a0">"</span>, <span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">Pred</span><span style="color:#4070a0">"</span>, <span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">True</span><span style="color:#4070a0">"</span>))
<span style="color:#007020;font-weight:700">print</span>(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">=</span><span style="color:#4070a0">"</span><span style="color:#666">*</span><span style="color:#40a070">30</span>)
<span style="color:#007020;font-weight:700">for</span> w, true, pred <span style="color:#007020;font-weight:700">in</span> <span style="color:#007020">zip</span>(X_te[i], y_te[i], p):
    <span style="color:#007020;font-weight:700">if</span> w <span style="color:#666">!=</span> <span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">__PAD__</span><span style="color:#4070a0">"</span>:
        <span style="color:#007020;font-weight:700">print</span>(<span style="color:#4070a0"></span><span style="color:#4070a0">"</span><span style="color:#4070a0">{:15}:{:5} ({})</span><span style="color:#4070a0">"</span><span style="color:#666">.</span>format(w, tags[pred], tags[true]))
</code></pre></div><button class="copy-code-button" type="button">Copy</button><pre><code>Word            Pred : (True)
==============================
Meanwhile      :O     (O)
,              :O     (O)
in             :O     (O)
Belgrade       :B-geo (B-geo)
,              :O     (O)
Serbia         :B-geo (B-geo)
's             :O     (O)
extreme        :O     (O)
nationalist    :O     (O)
Radical        :B-geo (B-org)
Party          :I-geo (I-org)
has            :O     (O)
filed          :O     (O)
a              :O     (O)
motion         :O     (O)
of             :O     (O)
no-confidence  :O     (O)
in             :O     (O)
the            :O     (O)
government     :O     (O)
of             :O     (O)
Prime          :B-per (B-per)
Minister       :I-per (O)
Vojislav       :B-per (B-per)
Kostunica      :I-per (I-per)
to             :O     (O)
protest        :O     (O)
the            :O     (O)
extradition    :O     (O)
of             :O     (O)
11             :O     (O)
suspects       :O     (O)
to             :O     (O)
the            :O     (O)
court          :O     (O)
since          :B-tim (B-tim)
October        :I-tim (I-tim)
.              :O     (O)
</code></pre><p>This looks pretty perfect! And it did require any feature engineering! With this architecture you should be able to achieve state-of-the-art results in multiple language related sequence tagging problems. Stay tuned for more NLP posts and try some of the proposed methods yourself.</p><p>Further readings:</p><ol><li>Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer. <a href="https://arxiv.org/pdf/1802.05365.pdf">“Deep contextualized word representations”</a></li></ol><hr><center><a href="https://www.buymeacoffee.com/tsterbak" target="_blank" onclick="plausible(&#39;buymecoffee_button&#39;)"><img src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/default-blue.webp" alt="Buy Me A Coffee" style="height:51px!important;width:217px!important;border-radius:9px"></a></center><hr><div class="related"><h3>Similar articles:</h3><ul><li><a href="https://www.depends-on-the-definition.com/lstm-with-char-embeddings-for-ner/">Enhancing LSTMs with character embeddings for Named entity recognition</a></li><li><a href="https://www.depends-on-the-definition.com/sequence-tagging-lstm-crf/">Sequence tagging with LSTM-CRFs</a></li><li><a href="https://www.depends-on-the-definition.com/guide-sequence-tagging-neural-networks-python/">Guide to sequence tagging with neural networks</a></li><li><a href="https://www.depends-on-the-definition.com/keras-and-eli5/">Explain neural networks with keras and eli5</a></li><li><a href="https://www.depends-on-the-definition.com/named-entity-recognition-conditional-random-fields-python/">Named entity recognition with conditional random fields in python</a></li></ul></div><hr><form action="https://depends-on-the-definition.us16.list-manage.com/subscribe/post?u=679cb933ef1e6038894b06b83&amp;id=4446721d7e" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate=""><label for="mce-EMAIL">Subscribe to the newsletter</label>
<input type="email" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required=""><div style="position:absolute;left:-5000px" aria-hidden="true"><input type="text" name="b_679cb933ef1e6038894b06b83_4446721d7e" tabindex="-1"></div><input type="submit" value="Subscribe" name="subscribe"></form></div></div></section><script src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/copycode.js.download"></script><section class="section"><div class="container has-text-centered"><p><a href="https://www.depends-on-the-definition.com/privacy/">Privacy</a>
<a href="https://www.depends-on-the-definition.com/imprint/">Imprint</a></p><p>© <a href="https://www.depends-on-the-definition.com/about/">depends-on-the-definition</a> 2017-2020</p></div></section><footer><script data-name="BMC-Widget" src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/widget.prod.min.js.download" data-id="tsterbak" data-description="Support me on Buy me a coffee!" data-message="Support me" data-color="#5F7FFF" data-position="right" data-x_margin="18" data-y_margin="18"></script><link rel="stylesheet" href="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous"><script defer="" src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/katex.min.js.download" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script><script defer="" src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/auto-render.min.js.download" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body,{delimiters:[{left:&#39;$$&#39;,right:&#39;$$&#39;,display:true},{left:&#39;$&#39;,right:&#39;$&#39;,display:false},]});"></script><script>feather.replace()</script></footer><div style="position: fixed; top: 0px; left: 0px; width: 0px; height: 0px; background: rgba(0, 0, 0, 0); text-align: center; z-index: 99999; transition: all 0.4s ease 0s;"><iframe style="position: fixed; margin: 0px; border: 0px; right: 18px; bottom: 98px; height: 0px; opacity: 0; width: calc(100vw - 38px); max-width: 320px; border-radius: 10px; box-shadow: rgba(0, 0, 0, 0.4) 0px 8px 16px; background: url(&quot;https://cdn.buymeacoffee.com/assets/img/widget/loader.svg&quot;) center center / 64px no-repeat rgb(255, 255, 255); z-index: 999999; transition: all 0.4s ease 0s; max-height: 620px;" src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/saved_resource.html"></iframe></div><div id="bmc-wbtn" style="display: flex; align-items: center; justify-content: center; width: 64px; height: 64px; background: rgb(95, 127, 255); color: white; border-radius: 32px; position: fixed; right: 18px; bottom: 18px; box-shadow: rgba(0, 0, 0, 0.4) 0px 4px 8px; z-index: 9999; cursor: pointer; font-weight: 600; transition: all 0.2s ease 0s;"><img src="./State-of-the-art named entity recognition with residual LSTM and ELMo _ Depends on the definition_files/coffee cup.svg" alt="Buy Me A Coffee" style="height: 40px; width: 40px; margin: 0; padding: 0;"></div><div style="position: fixed; display: block; opacity: 1; right: 102px; bottom: 16px; background: rgb(255, 255, 255); z-index: 9999; transition: all 0.4s ease 0s; box-shadow: rgba(0, 0, 0, 0.3) 0px 4px 8px; padding: 16px; border-radius: 4px; font-size: 14px; color: rgb(0, 0, 0); width: auto; max-width: 260px; line-height: 1.5; font-family: &quot;Avenir Book1&quot;, &quot;Avenir Book2&quot;, &quot;Avenir Book3&quot;, &quot;Avenir Book4&quot;, &quot;Avenir Book5&quot;, &quot;Avenir Book6&quot;, sans-serif;">Support me</div></body></html>